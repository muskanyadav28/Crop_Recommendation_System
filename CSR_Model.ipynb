{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7bfc61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50874f8",
   "metadata": {},
   "source": [
    "# 1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5a8baaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Shape: (4991, 10)\n",
      "Columns: ['nitrogen', 'phosphorus', 'potassium', 'ph', 'temperature', 'humidity', 'rainfall', 'soil', 'season', 'crop']\n",
      "\n",
      "Missing Values:\n",
      "nitrogen       0\n",
      "phosphorus     0\n",
      "potassium      0\n",
      "ph             0\n",
      "temperature    0\n",
      "humidity       0\n",
      "rainfall       0\n",
      "soil           0\n",
      "season         0\n",
      "crop           0\n",
      "dtype: int64\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4991 entries, 0 to 4990\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   nitrogen     4991 non-null   float64\n",
      " 1   phosphorus   4991 non-null   float64\n",
      " 2   potassium    4991 non-null   float64\n",
      " 3   ph           4991 non-null   float64\n",
      " 4   temperature  4991 non-null   float64\n",
      " 5   humidity     4991 non-null   float64\n",
      " 6   rainfall     4991 non-null   float64\n",
      " 7   soil         4991 non-null   object \n",
      " 8   season       4991 non-null   object \n",
      " 9   crop         4991 non-null   object \n",
      "dtypes: float64(7), object(3)\n",
      "memory usage: 390.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"Backend/ml/data/crop_recommendation_dataset_updated.csv\")\n",
    "\n",
    "print(f\"\\nDataset Shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(f\"\\nMissing Values:\\n{df.isnull().sum()}\")\n",
    "print(f\"\\nDataset Info:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147aba12",
   "metadata": {},
   "source": [
    "# 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02855ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Matrix Shape: (4991, 9)\n",
      "  Soil Types (9): ['Alluvial', 'Black Soil', 'Clay', 'Clay Loam', 'Coastal Sandy', 'Loamy', 'Red Soil', 'Sandy', 'Sandy Loam']\n",
      "  Seasons (3): ['Kharif', 'Rabi', 'Zayad']\n",
      "  Crops (23): ['Apple', 'Banana', 'Blackgram', 'Chickpea', 'Coconut', 'Coffee', 'Cotton', 'Grapes', 'Jute', 'KidneyBeans', 'Lentil', 'Maize', 'Mango', 'MothBeans', 'MungBean', 'Muskmelon', 'Orange', 'Papaya', 'PigeonPeas', 'Pomegranate', 'Rice', 'Watermelon', 'Wheat']\n"
     ]
    }
   ],
   "source": [
    "NUMERICAL_FEATURES = [\n",
    "    \"nitrogen\",\n",
    "    \"phosphorus\",\n",
    "    \"potassium\",\n",
    "    \"temperature\",\n",
    "    \"humidity\",\n",
    "    \"ph\",\n",
    "    \"rainfall\"\n",
    "]\n",
    "\n",
    "TARGET = \"crop\"\n",
    "\n",
    "# Encode categorical features\n",
    "soil_encoder = LabelEncoder()\n",
    "season_encoder = LabelEncoder()\n",
    "crop_encoder = LabelEncoder()\n",
    "\n",
    "df['soil_encoded'] = soil_encoder.fit_transform(df['soil'])\n",
    "df['season_encoded'] = season_encoder.fit_transform(df['season'])\n",
    "y_encoded = crop_encoder.fit_transform(df[TARGET])\n",
    "\n",
    "# Feature matrix\n",
    "ENCODED_FEATURES = NUMERICAL_FEATURES + ['soil_encoded', 'season_encoded']\n",
    "X = df[ENCODED_FEATURES]\n",
    "\n",
    "print(f\"\\nFeature Matrix Shape: {X.shape}\")\n",
    "print(f\"  Soil Types ({len(soil_encoder.classes_)}): {list(soil_encoder.classes_)}\")\n",
    "print(f\"  Seasons ({len(season_encoder.classes_)}): {list(season_encoder.classes_)}\")\n",
    "print(f\"  Crops ({len(crop_encoder.classes_)}): {list(crop_encoder.classes_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13002629",
   "metadata": {},
   "source": [
    "# 3. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "473c0afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Split:\n",
      "  Training set: 3992 samples (80.0%)\n",
      "  Testing set: 999 samples (20.0%)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y_encoded,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_encoded\n",
    ")\n",
    "\n",
    "print(f\"\\nDataset Split:\")\n",
    "print(f\"  Training set: {X_train.shape[0]} samples ({(X_train.shape[0]/len(X))*100:.1f}%)\")\n",
    "print(f\"  Testing set: {X_test.shape[0]} samples ({(X_test.shape[0]/len(X))*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe97502",
   "metadata": {},
   "source": [
    "# 4. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "770296d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training Random Forest Classifier...\n",
      "============================================================\n",
      "Model training completed!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training Random Forest Classifier...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=20,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Model training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64c3211",
   "metadata": {},
   "source": [
    "# 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b415132c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MODEL PERFORMANCE EVALUATION\n",
      "============================================================\n",
      "\n",
      "Accuracy Scores:\n",
      "  Training Accuracy: 99.70%\n",
      "  Testing Accuracy:  97.40%\n",
      "  Difference:        2.30%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL PERFORMANCE EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Training accuracy\n",
    "y_train_pred = model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "# Testing accuracy\n",
    "y_test_pred = model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"\\nAccuracy Scores:\")\n",
    "print(f\"  Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "print(f\"  Testing Accuracy:  {test_accuracy * 100:.2f}%\")\n",
    "print(f\"  Difference:        {(train_accuracy - test_accuracy) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c13ff9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overfitting Analysis:\n",
      "  Model is WELL-GENERALIZED\n",
      "  (Training and testing accuracies are similar)\n"
     ]
    }
   ],
   "source": [
    "# Overfitting check\n",
    "print(f\"\\nOverfitting Analysis:\")\n",
    "if train_accuracy - test_accuracy > 0.10:\n",
    "    print(\"  WARNING: Model is OVERFITTING\")\n",
    "    print(\"  (Training accuracy is significantly higher than testing accuracy)\")\n",
    "elif train_accuracy - test_accuracy > 0.05:\n",
    "    print(\"  MODERATE overfitting detected\")\n",
    "    print(\"  (Training accuracy is slightly higher than testing accuracy)\")\n",
    "else:\n",
    "    print(\"  Model is WELL-GENERALIZED\")\n",
    "    print(\"  (Training and testing accuracies are similar)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94f335b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation (5-fold):\n",
      "  CV Scores: ['96.50%', '96.89%', '96.39%', '96.69%', '95.99%']\n",
      "  Mean CV Accuracy: 96.49%\n",
      "  Std Deviation: 0.30%\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation\n",
    "print(f\"\\nCross-Validation (5-fold):\")\n",
    "cv_scores = cross_val_score(model, X, y_encoded, cv=5, scoring='accuracy')\n",
    "print(f\"  CV Scores: {[f'{score*100:.2f}%' for score in cv_scores]}\")\n",
    "print(f\"  Mean CV Accuracy: {cv_scores.mean() * 100:.2f}%\")\n",
    "print(f\"  Std Deviation: {cv_scores.std() * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f930831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Apple       1.00      1.00      1.00        43\n",
      "      Banana       1.00      1.00      1.00        43\n",
      "   Blackgram       0.95      0.95      0.95        43\n",
      "    Chickpea       0.98      0.95      0.96        43\n",
      "     Coconut       1.00      1.00      1.00        44\n",
      "      Coffee       1.00      1.00      1.00        43\n",
      "      Cotton       1.00      1.00      1.00        44\n",
      "      Grapes       1.00      1.00      1.00        44\n",
      "        Jute       1.00      1.00      1.00        43\n",
      " KidneyBeans       1.00      0.93      0.96        43\n",
      "      Lentil       0.96      1.00      0.98        44\n",
      "       Maize       1.00      1.00      1.00        43\n",
      "       Mango       1.00      0.95      0.98        43\n",
      "   MothBeans       1.00      1.00      1.00        43\n",
      "    MungBean       0.98      1.00      0.99        44\n",
      "   Muskmelon       0.75      0.95      0.84        43\n",
      "      Orange       0.98      1.00      0.99        44\n",
      "      Papaya       1.00      1.00      1.00        43\n",
      "  PigeonPeas       0.98      0.98      0.98        44\n",
      " Pomegranate       0.98      1.00      0.99        44\n",
      "        Rice       1.00      1.00      1.00        43\n",
      "  Watermelon       0.94      0.68      0.79        44\n",
      "       Wheat       0.98      1.00      0.99        44\n",
      "\n",
      "    accuracy                           0.97       999\n",
      "   macro avg       0.98      0.97      0.97       999\n",
      "weighted avg       0.98      0.97      0.97       999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Detailed classification report\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(\n",
    "    y_test, \n",
    "    y_test_pred, \n",
    "    target_names=crop_encoder.classes_,\n",
    "    zero_division=0\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cec3bd38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Importance:\n",
      "============================================================\n",
      "  potassium      : 0.1991 (19.91%)\n",
      "  rainfall       : 0.1808 (18.08%)\n",
      "  nitrogen       : 0.1689 (16.89%)\n",
      "  phosphorus     : 0.1414 (14.14%)\n",
      "  humidity       : 0.0878 (8.78%)\n",
      "  temperature    : 0.0859 (8.59%)\n",
      "  season         : 0.0582 (5.82%)\n",
      "  soil           : 0.0488 (4.88%)\n",
      "  ph             : 0.0289 (2.89%)\n"
     ]
    }
   ],
   "source": [
    "# Feature importance\n",
    "print(f\"\\nFeature Importance:\")\n",
    "print(\"=\"*60)\n",
    "feature_names = NUMERICAL_FEATURES + ['soil', 'season']\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "for idx, row in feature_importance.iterrows():\n",
    "    print(f\"  {row['Feature']:15s}: {row['Importance']:.4f} ({row['Importance']*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fd05a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix Summary:\n",
      "  Correct Predictions: 973\n",
      "  Incorrect Predictions: 26\n",
      "  Total Test Samples: 999\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix Summary\n",
    "print(f\"\\nConfusion Matrix Summary:\")\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "print(f\"  Correct Predictions: {np.trace(cm)}\")\n",
    "print(f\"  Incorrect Predictions: {cm.sum() - np.trace(cm)}\")\n",
    "print(f\"  Total Test Samples: {cm.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d28dc653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Per-Class Accuracy:\n",
      "  Apple          : 100.00%\n",
      "  Banana         : 100.00%\n",
      "  Blackgram      : 95.35%\n",
      "  Chickpea       : 95.35%\n",
      "  Coconut        : 100.00%\n",
      "  Coffee         : 100.00%\n",
      "  Cotton         : 100.00%\n",
      "  Grapes         : 100.00%\n",
      "  Jute           : 100.00%\n",
      "  KidneyBeans    : 93.02%\n",
      "  Lentil         : 100.00%\n",
      "  Maize          : 100.00%\n",
      "  Mango          : 95.35%\n",
      "  MothBeans      : 100.00%\n",
      "  MungBean       : 100.00%\n",
      "  Muskmelon      : 95.35%\n",
      "  Orange         : 100.00%\n",
      "  Papaya         : 100.00%\n",
      "  PigeonPeas     : 97.73%\n",
      "  Pomegranate    : 100.00%\n",
      "  Rice           : 100.00%\n",
      "  Watermelon     : 68.18%\n",
      "  Wheat          : 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Per-class accuracy\n",
    "print(f\"\\nPer-Class Accuracy:\")\n",
    "for i, crop_name in enumerate(crop_encoder.classes_):\n",
    "    if cm[i].sum() > 0:\n",
    "        class_accuracy = cm[i][i] / cm[i].sum()\n",
    "        print(f\"  {crop_name:15s}: {class_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1b45e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING SUMMARY\n",
      "============================================================\n",
      "\n",
      "Model Training: COMPLETED\n",
      "Training Accuracy: 99.70%\n",
      "Testing Accuracy: 97.40%\n",
      "Cross-Validation Accuracy: 96.49%\n",
      "Overfitting Status: Well-Generalized\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nModel Training: COMPLETED\")\n",
    "print(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "print(f\"Testing Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "print(f\"Cross-Validation Accuracy: {cv_scores.mean() * 100:.2f}%\")\n",
    "print(f\"Overfitting Status: {'Well-Generalized' if train_accuracy - test_accuracy <= 0.05 else 'Overfitting Detected'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef43350",
   "metadata": {},
   "source": [
    "# Save the trained model and encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ff52e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model saved successfully!\n",
      "✓ Soil encoder saved successfully!\n",
      "✓ Season encoder saved successfully!\n",
      "✓ Crop encoder saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "joblib.dump(model, 'Backend/ml/models/crop_recommendation_model.pkl')\n",
    "print(\"✓ Model saved successfully!\")\n",
    "\n",
    "# Save encoders\n",
    "joblib.dump(soil_encoder, 'Backend/ml/models/soil_encoder.pkl')\n",
    "print(\"✓ Soil encoder saved successfully!\")\n",
    "\n",
    "joblib.dump(season_encoder, 'Backend/ml/models/season_encoder.pkl')\n",
    "print(\"✓ Season encoder saved successfully!\")\n",
    "\n",
    "joblib.dump(crop_encoder, 'Backend/ml/models/crop_encoder.pkl')\n",
    "print(\"✓ Crop encoder saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
